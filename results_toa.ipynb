{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Any, cast\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from models import models, scalers\n",
    "from read_data import read_datasets\n",
    "from data_cleaning import prep_dataframe, preprocess_data\n",
    "from training import train_test_random, split_x_y, calc_stats"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Datasets\n",
    "\n",
    "Copies of the dataset, each with a different scaler applies, are generated and stored for usage in training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "dep_var = \"Log(Efficiency)\"\n",
    "\n",
    "all_data = read_datasets()\n",
    "combined_data = prep_dataframe(all_data, dep_var)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "datasets = {}\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    data, _ = preprocess_data(combined_data.copy(), dep_var, scaler, True)\n",
    "\n",
    "    non_holdout, holdout = train_test_random(data, 0.1)\n",
    "    train, test = train_test_random(non_holdout, 0.1)\n",
    "\n",
    "    # Do splits for all data\n",
    "    datasets[scaler_name] = split_x_y([train, test, holdout], dep_var)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results = pd.DataFrame(columns=[\"name\", \"scaler\", \"r2\", \"mae\", \"mape\", \"mse\"])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    for scaler_name in scalers.keys():\n",
    "        train, test, holdout = datasets[scaler_name]\n",
    "        model.fit(train[0], train[1])\n",
    "\n",
    "        pred_y = model.predict(test[0])\n",
    "        result = calc_stats(test[1], pred_y, print_res=False)\n",
    "        result = cast(dict[str, Any], result)\n",
    "        result[\"name\"] = model_name\n",
    "        result[\"scaler\"] = scaler_name\n",
    "\n",
    "        results = results.append(result, ignore_index=True)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "results.to_csv(\"results.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Take only the maximum scaler config for each model\n",
    "max_indices = results.groupby([\"name\"])[\"r2\"].idxmax()\n",
    "maximums = results.loc[max_indices]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "maximums.to_csv(\"results.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "32c98c724f4dc158d685d7f352a5521c40874805d8d14b99c4302dfd329e583c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}