{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from typing import Any, cast\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "\n",
    "from models import models, scalers\n",
    "from read_data import read_datasets\n",
    "from data_cleaning import prep_dataframe, DataCleaner\n",
    "from training import train_test_random, split_x_y, calc_stats"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Generate Datasets\n",
    "\n",
    "Copies of the dataset, each with a different scaler applies, are generated and stored for usage in training."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "dep_var = \"Log(Rmax)\"\n",
    "use_crossval = True\n",
    "\n",
    "all_data = read_datasets()\n",
    "combined_data = prep_dataframe(all_data, dep_var)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "TOP500_201906.xls\n",
      "TOP500_202011.xlsx\n",
      "TOP500_201911.xls\n",
      "TOP500_202006.xlsx\n",
      "TOP500_201811.xls\n",
      "TOP500_201806.xls\n",
      "TOP500_201206.xls\n",
      "TOP500_201211.xls\n",
      "TOP500_201406.xls\n",
      "TOP500_202106.xlsx\n",
      "TOP500_201611.xls\n",
      "TOP500_201411.xls\n",
      "TOP500_201606.xls\n",
      "TOP500_201311.xls\n",
      "TOP500_201306.xls\n",
      "TOP500_201111.xls\n",
      "TOP500_201511.xls\n",
      "TOP500_201706.xls\n",
      "TOP500_201506.xls\n",
      "TOP500_201711.xls\n",
      "Unknown processor: 'NEC', full name: 'NEC  3.200GHz' @ Earth Simulator, 2009\n",
      "Unknown processor: 'NEC', full name: 'NEC  3.200GHz' @ Earth Simulator, 2009\n",
      "Unknown processor: 'NEC', full name: 'NEC  3.200GHz' @ Earth Simulator, 2009\n",
      "Unknown processor: 'NEC', full name: 'NEC  3.200GHz' @ Earth Simulator, 2009\n",
      "Unknown processor: 'NEC', full name: 'NEC  3.20GHz' @ Earth Simulator, 2009\n",
      "Unknown processor: 'Xeon EM64T', full name: 'Xeon EM64T  3.60GHz' @ Thunderbird, 2006\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "datasets = {}\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    data = DataCleaner(scaler, dep_var).fit_transform(combined_data.copy())\n",
    "\n",
    "    non_holdout, holdout = train_test_random(data, 0.1)\n",
    "    train, test = train_test_random(non_holdout, 0.1)\n",
    "\n",
    "    if use_crossval:\n",
    "        # We'll do splits later\n",
    "        datasets[scaler_name] = data\n",
    "    else:\n",
    "        # Do splits for all data\n",
    "        datasets[scaler_name] = split_x_y([train, test, holdout], dep_var)\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Filtered duplicates to go from 10000 rows to 2476\n",
      "Filtered duplicates to go from 10000 rows to 2476\n",
      "Filtered duplicates to go from 10000 rows to 2476\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "if use_crossval:\n",
    "    results = pd.DataFrame(columns=[\"name\", \"scaler\", \"avg r2\"])\n",
    "else:\n",
    "    results = pd.DataFrame(columns=[\"name\", \"scaler\", \"r2\", \"mae\", \"mape\", \"mse\"])\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    print(model_name)\n",
    "    for scaler_name in scalers.keys():\n",
    "        if use_crossval:\n",
    "            all_r2 = []\n",
    "            for i in range(20):\n",
    "                m = clone(model)\n",
    "                train, test = train_test_random(datasets[scaler_name], 0.1)\n",
    "                (train_X, train_y), (test_X, test_y) = split_x_y([train, test], dep_var)\n",
    "                model.fit(train_X, train_y)\n",
    "\n",
    "                pred_y = model.predict(test_X)\n",
    "                result = calc_stats(test_y, pred_y, print_res=False)\n",
    "                result = cast(dict[str, Any], result)\n",
    "                all_r2.append(result[\"r2\"])\n",
    "\n",
    "            result = {\n",
    "                \"name\": model_name,\n",
    "                \"scaler\": scaler_name,\n",
    "                \"avg r2\": np.average(all_r2)\n",
    "            }\n",
    "        else:\n",
    "            train, test, holdout = datasets[scaler_name]\n",
    "            model.fit(train[0], train[1])\n",
    "\n",
    "            pred_y = model.predict(test[0])\n",
    "            result = calc_stats(test[1], pred_y, print_res=False)\n",
    "            result = cast(dict[str, Any], result)\n",
    "            result[\"name\"] = model_name\n",
    "            result[\"scaler\"] = scaler_name\n",
    "\n",
    "        results = results.append(result, ignore_index=True)\n"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4v/ps0_pwf52rd0x9m9hjkntgbh0000gn/T/ipykernel_11707/3744963559.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_random\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscaler_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_x_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdep_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                 \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSGenome/ML-rewrite/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'i'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m         \u001b[0;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Developer/CSGenome/ML-rewrite/.venv/lib/python3.9/site-packages/sklearn/svm/_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msupport_vectors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_support\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdual_coef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_probA\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m             self._probB, self.fit_status_ = libsvm.fit(\n\u001b[0m\u001b[1;32m    278\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m                 \u001b[0msvm_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msolver_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "results.to_csv(\"results.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "# Take only the maximum scaler config for each model\n",
    "max_indices = results.groupby([\"name\"])[\"r2\"].idxmax()\n",
    "maximums = results.loc[max_indices]\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "maximums.to_csv(\"results.csv\")\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.venv': venv)"
  },
  "interpreter": {
   "hash": "32c98c724f4dc158d685d7f352a5521c40874805d8d14b99c4302dfd329e583c"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}